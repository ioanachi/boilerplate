# -*- coding: utf-8 -*-
"""Tutorial_keras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gzg6s1MvtXQE63yDY_OXF3jqHuf8CEoD
"""

from tensorflow.keras.utils import plot_model

"""### Import packages"""

import numpy as np
import matplotlib.pyplot as plt
import os


#Setting TF_CPP_MIN_LOG_LEVEL to "2" means that only ERROR messages will be displayed, and INFO and WARNING messages will be suppressed.
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"


from sklearn.datasets import make_circles
from sklearn.model_selection import train_test_split

from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping
from keras.utils import plot_model

"""### Create plots that will be used for the model visualization

"""

def plot_data(pl, X, y):
  #plot class where y==0
  pl.plot(X[y==0,0], X[y==0.1], "ob", aplpha=0.5)
  #plot class where y==1
  pl.plot(X[y==1,0], X[y==1.1], "xr", aplpha=0.5)
  pl.legend(['0','1'])
  return pl

def plot_decision_boundary(model, X, y):

  # Generate evenly spaced points within the range of the features
  amin, bmin=X.min(axis=0) -0.1
  amax, bmax=X.max(axis=0) +0.1

  # Create a grid of points
  hticks = np.linspace(amin, amax, 101)
  vticks = np.linspace(bmin, bmax, 101)

  aa, bb = np.meshgrid(hticks, vticks)
  ab = np.c_[aa.ravel(), bb.ravel()]
  # Rest of the plotting code (not shown in the provided snippet)
  # You need to add code here to calculate predictions and create the plot

  predictions = model.predict(ab)
  plt.contourf(aa, bb, predictions.reshape(aa.shape), alpha=0.5)
  plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')
  plt.xlabel('Feature 1')
  plt.ylabel('Feature 2')
  plt.title('Decision Boundary')
  return plt

"""### Split in train, test datasets"""

X, y = make_circles(n_samples=1000, factor=.6, noise=0.1, random_state=42)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

X_train

y_train

"""## Create the keras Model
# add the input shape to the first layer
"""

model = Sequential()
#add the input shape to the first layer
model.add(Dense(4, input_shape=(2,),activation="tanh", name="Layer_hidden_1"))
model.add(Dense(4, activation="tanh", name="Layer_hidden_2"))
model.add(Dense(1, input_shape=(2,),activation="sigmoid",  name="Layer_hidden_last"))
model.compile(Adam(learning_rate=0.05), 'binary_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=100, verbose=1)

eval_result = model.evaluate(X_test, y_test)

print(f'Test loss: {eval_result[0]} \nTest accuracy: {eval_result[1]}')

plot_decision_boundary(model, X, y).show()

"""## Model summary offers the summary for the

layers

 input shape

 nr of trainable paramsn

 output of stdout
"""

model.summary()

"""## Plot model

model layer hierarchy
shows connections4

outpput is graphic file

presentation quality


"""

plot_model(model, to_file='model.png',show_shapes=True
)

"""## Callbacks are used for :

collect info on training

monitor training

tune params while training

create checkpoints

terminate training early - if it stops improving

Api for userdefined callbacks
"""

# monitor accuracy
# patience = 5 =. stop after 5 epochs if not improving accuracy
# mode => if the quantity should be increasin or decreasing


my_callbacks = [EarlyStopping(monitor='val_accuracy', patience=5, mode=max)]

model.summary()
model.fit(X_train, y_train, epochs=100, verbose=1, callbacks=my_callbacks, validation_data=(X_test, y_test))

"""### Sequential Model

Input --> Layer 1 ---> Layer 2 ---> Layer3 --> Output

## Use the functional API to create different types of models and add different layers


- can pass a list of layers for input or output
"""

from keras.models import Model
from keras.layers import Input


inputs = Input(shape=(2,))
layers_hidden1 = Dense(4, activation='tanh', name="Hidden_1")(inputs)
layers_hidden2 = Dense(4, activation='tanh', name="Hidden_2")(layers_hidden1)
output_layer = Dense(1, activation="sigmoid", name="Output_layer")(layers_hidden2)

model = Model(inputs=inputs, outputs= output_layer)
model.summary()

model.compile(Adam(learning_rate=0.05), 'binary_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=100, verbose=1, callbacks=my_callbacks, validation_data=(X_test, y_test))

plot_decision_boundary(model, X, y).show()

eval_result = model.evaluate(X_test, y_test)

"""## Common methods

1 The get_weights() method is useful for various purposes, such as:

    Saving and loading models: You can use get_weights() to retrieve the model's weights before saving them to a file and later set the weights back to the model after loading them from the file.

    Weight initialization: You can use the get_weights() method to examine the initialized weights of the model to understand how the model starts its training process.

    Weight analysis: You can inspect the values of the weights and biases to understand the model's behavior, convergence, and possible issues such as vanishing or exploding gradients.

    Transfer learning: When using transfer learning, you might want to freeze certain layers of a pre-trained model. You can retrieve the weights of those layers, store them separately, and later set them back when needed.

Remember that when using the get_weights() method, the model or layer must be already built and compiled. Otherwise, you will get an error because the weights are created during the build process.

The set_weights() method is useful for various purposes, such as:

    Transfer learning: When using transfer learning, you might want to set the weights of certain layers with pre-trained values. This is often done to freeze the weights of some layers to retain the learned features while training only the newly added layers for the specific task.

    Model initialization: You can use the set_weights() method to initialize the model with custom or specific weights before training.

    Weight fine-tuning: After training a model, you might want to modify or fine-tune the model's weights based on specific criteria. You can use set_weights() to apply these changes.

    Weight restoration: When loading a pre-trained model from a file, you can use the set_weights() method to set the weights of the model with the loaded values.

Please note that when using the set_weights() method, the shapes of the provided weight matrices and bias vectors must match the shapes of the corresponding layers in the model. If the shapes do not match, you will encounter errors during the setting process. Also, make sure the model is already built and compiled before using set_weights(), as the method sets the weights directly and doesn't perform any additional checks on the model architecture.
"""

